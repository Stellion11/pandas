# PCA, FI ì‚¬ìš©ë§ê³  PF ì´ìš©í•˜ì—¬ ë‹¨ìˆœ ì¦í­
import numpy as np
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
import time

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures


from xgboost import XGBClassifier, XGBRegressor

seed = 123
random.seed(seed)
np.random.seed(seed)

# 1. ë°ì´í„°
path = './_data/kaggle/bike/'           # ìƒëŒ€ê²½ë¡œ : ëŒ€ì†Œë¬¸ì êµ¬ë¶„X

train_csv = pd.read_csv(path + 'train.csv', index_col=0)
test_csv = pd.read_csv(path + 'test.csv', index_col=0)
submission_csv = pd.read_csv(path + 'sampleSubmission.csv')

print(train_csv.columns)
# ['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',
#        'humidity', 'windspeed', 'casual', 'registered', 'count']

x = train_csv.drop(['count'], axis=1)
y = train_csv['count']

# 1. ì´ìƒì¹˜ ì‹œê°ì ìœ¼ë¡œ í™•ì¸
def plot_boxplot(data):
    plt.boxplot(data)
    plt.title("Boxplot of all columns")
    plt.xlabel("Feature Index")
    plt.ylabel("Value")
    plt.show()

# plot_boxplot(x)

def detect_outliers_all(data, feature_names=None, iqr_scale=1.5):
    data_np = data.values  # ğŸ”¸ DataFrame â†’ numpy ë³€í™˜
    n_cols = data_np.shape[1]
    outlier_results = []

    for col in range(n_cols):
        col_data = data_np[:, col]
        q1 = np.percentile(col_data, 25)
        q2 = np.percentile(col_data, 50)
        q3 = np.percentile(col_data, 75)
        iqr = q3 - q1
        lower_bound = q1 - iqr_scale * iqr
        upper_bound = q3 + iqr_scale * iqr

        outlier_idx = np.where((col_data < lower_bound) | (col_data > upper_bound))[0]

        if len(outlier_idx) > 0:
            col_name = feature_names[col] if feature_names else data.columns[col]
            print(f"\nğŸ“Œ {col_name}")
            print(f"  Q1 = {q1:.4f}, Q3 = {q3:.4f}, IQR = {iqr:.4f}")
            print(f"  ì´ìƒì¹˜ ë²”ìœ„: < {lower_bound:.4f} ë˜ëŠ” > {upper_bound:.4f}")
            print(f"  ì´ìƒì¹˜ ì¸ë±ìŠ¤ ìˆ˜: {len(outlier_idx)}")
            print(f"  ì´ìƒì¹˜ ê°’ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ): {col_data[outlier_idx[:10]]}")

            outlier_results.append({
                'column': col_name,
                'indices': outlier_idx,
                'values': col_data[outlier_idx]
            })

    if not outlier_results:
        print("ğŸ‰ ì´ìƒì¹˜ ì—†ìŒ (ëª¨ë“  ì»¬ëŸ¼)")

    return outlier_results

detect_outliers_all(x)
'''
ğŸ“Œ humidity
  Q1 = 47.0000, Q3 = 77.0000, IQR = 30.0000
  ì´ìƒì¹˜ ë²”ìœ„: < 2.0000 ë˜ëŠ” > 122.0000
  ì´ìƒì¹˜ ì¸ë±ìŠ¤ ìˆ˜: 22
  ì´ìƒì¹˜ ê°’ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]

ğŸ“Œ windspeed
  Q1 = 7.0015, Q3 = 16.9979, IQR = 9.9964
  ì´ìƒì¹˜ ë²”ìœ„: < -7.9931 ë˜ëŠ” > 31.9925
  ì´ìƒì¹˜ ì¸ë±ìŠ¤ ìˆ˜: 227
  ì´ìƒì¹˜ ê°’ ì˜ˆì‹œ (ìµœëŒ€ 10ê°œ): [32.9975 36.9974 35.0008 35.0008 39.0007 35.0008 35.0008 36.9974 32.9975
 36.9974]

'''
# ìœ„ì— ë‘ ì»¬ëŸ¼ë§Œ ì´ìƒì¹˜ ì²˜ë¦¬

####### xì™€ y ë¶„ë¦¬ ######
x = train_csv.drop(['casual', 'registered', 'count'], axis=1)    # testì…‹ì—ëŠ” ì—†ëŠ” casual, registered, yê°€ ë  countëŠ” xì—ì„œ ì œê±°
# y = train_csv['count'] # ìœ„ì—ì„œ ì´ë¯¸ í•´ì¤Œ

# ì´ìƒì¹˜_humidity
x.loc[x['humidity'] == 0, 'humidity'] = np.nan
x['humidity'] = x['humidity'].interpolate()  # ì„ í˜• ë³´ê°„

# ì´ìƒì¹˜_windspeed
# í‰ê· /ë³´ê°„ ë“±ìœ¼ë¡œ ëŒ€ì²´
x.loc[x['windspeed'] > 31.9925, 'windspeed'] = np.nan
x['windspeed'] = x['windspeed'].interpolate()

x_train, x_test, y_train, y_test = train_test_split(
    x, y, train_size=0.8, random_state=seed,
    # stratify=y
)

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

#2. ëª¨ë¸
model = RandomForestRegressor(random_state=seed)

start = time.time()
model.fit(x_train, y_train)
end = time.time()

#4. í‰ê°€, ì˜ˆì¸¡
y_pred = model.predict(x_test)

#í‰ê°€
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("RÂ²:", r2)
print("RMSE:", rmse)
print("ê±¸ë¦°ì‹œê°„:", round(end - start, 2), 'ì´ˆ')

# RÂ²: 0.2772909613252007
# RMSE: 152.08695010773602
# ê±¸ë¦°ì‹œê°„: 9.4 ì´ˆ

# RÂ²: 0.2661665541443171
# RMSE: 153.2529907149747
# ê±¸ë¦°ì‹œê°„: 1.68 ì´ˆ